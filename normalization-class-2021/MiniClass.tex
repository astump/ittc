\documentclass{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{url}
\usepackage{natbib}
\usepackage{proof}
\usepackage{stmaryrd}
\usepackage{mathabx}
\usepackage{parskip}
\usepackage{fullpage}
\usepackage[tocflat]{tocstyle}
\setcounter{tocdepth}{2}

\bibliographystyle{plainnat}

\providecommand{\betarule}[0]{\infer[\beta]{(\lambda\,x.\, t)\ t'\ \leadsto\ [t'/x]t}
                                {\ }}
\providecommand{\lamrule}[0]{\infer[\textit{lam}]{\lambda\,x.\, t\ \leadsto\ \lambda\,x.\, t'}
                               {t\ \leadsto\ t'}}
\providecommand{\apparule}[0]{\infer[\textit{app1}]{(t_1\ t_2)\ \leadsto\ (t_1'\ t_2)}
                                {t_1\ \leadsto\ t_1'}}
\providecommand{\appbrule}[0]{\infer[\textit{app2}]{(t_1\ t_2)\ \leadsto\ (t_1\ t_2')}
                                {t_2\ \leadsto\ t_2'}}

\usepackage[pdftex,
	pdfauthor={Aaron Stump},
	pdftitle={ITTC Class on Normalization},
	linktocpage,
	urlcolor={black},
	linkcolor={black},
        citecolor={black}]{hyperref}

\begin{document}

\newcommand{\interp}[1]{\llbracket #1 \rrbracket} 
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}

\title{Mini Class on Normalization in Type Theory\\
{\large\emph{The Iowa Type Theory Commute}}}


\author{Aaron Stump\\
  Computer Science \\
  The University of Iowa}

\maketitle

\tableofcontents

\section{Introduction}

The issue of whether or not programs terminate is of significant
theoretical and practical importance in Computer Science.  We will
study one aspect of this topic, namely the normalization property for
several different typed lambda calculi.  Lambda calculus is a
minimalistic programming language, whose central feature of anonymous
functions is now found in most mainstream languages.  We will review
this below.  Functional programming languages like LISP, Scheme,
Haskell, and the various forms of ML (like OCaml) are based on lambda
calculus, with Haskell and ML using statically typed versions.

Typed lambda calculus is also the core of proof assistants based on
constructive type theory, like Coq and Agda.  To ensure logical
soundness of the theories implemented by these tools, it is necessary
to ensure that all programs terminate.  This is because, under the
Curry-Howard isomorphism, proofs are identified with programs.  For
example, proofs by induction are identified with recursive programs:
invoking the induction hypothesis in the proof is the same as making a
recursive call.  But then potentially diverging programs correspond to
potentially unsound inductions, and must be banned by the system.
Otherwise, one could prove any formula using a diverging function as
the proof.  

In this short class, we will see proofs of normalization properties
for several different type theories, namely simply typed lambda
calculus (STLC), System F (polymorphic lambda calculus), and System
$F_\omega$ (a generalization of System F).  These theories are
described below.  Let us begin with some basic definitions for typed
lambda calculi.

\section{Basics of Untyped Lambda Calculus}

Lambda calculus expressions are called terms.  The syntax for terms $t$
is:
\[
\textit{terms}\ t\ \  ::=\ \  x\ |\ t\ t'\ |\ \lambda\,x.\, t
\]
\noindent Here, $x$ is for variables, $t\ t'$ is for
\textbf{applications} of $t$ as a function to $t'$ as an argument, and
$\lambda\,x.\, t$ is a \textbf{lambda-abstraction}, an anonymous
function which takes input $x$ and returns output $t$.  The $\lambda$
in $\lambda\,x.t$ is said to bind $x$ in $t$.  It introduces local
variable $x$ within the \textbf{body} $t$ of the lambda abstraction.

(Note that we are here following the common practice of introducing a
specific family of meta-variables -- namely $t$ and variants like
$t'$, $t_1$, etc. -- to refer to a specific set of mathematical
objects, in this case terms.  Anywhere you see a $t$, you should
understand that it is referring to some term as defined by the above
syntax.)

\subsection{$\beta$-reduction}

To define how programs (terms) of lambda calculus run, the central
idea is so-called $\beta$-reduction.  It says that an anonymous
function applied to an argument can be reduced by substituting the
argument for the bound variable in the body of the function.  This
basic idea is expressed by defining a binary relation $\leadsto$ on
terms by this rule:
\[
\infer[\beta]{(\lambda\,x.\, t)\ t'\ \leadsto\ [t'/x]t}
                                {\ }
\]
\noindent $[t'/x]t$ denotes the term one gets by capture-avoiding substitution
of $t'$ for $x$ in $t$.  Capture-avoiding means that the scoping of variables
should not change when doing the substitution.  So substituting $x\ x$ for $y$
in $\lambda\,x.\, y$, for example, should \underline{not} give us $\lambda x.\, (x\ x)$,
because the scoping of $x$ in $x\ x$ is global, but would become local
if the result were $\lambda x.\, (x\ x)$.  Instead, one may rename the bound variable
to avoid such capture, giving a result like $\lambda y.\, (x\ x)$ instead.  It
is actually rather tricky to get the details for substitution exactly right,
both in theory and in practice.  We will content ourselves with the idea
that we must rename bound variables to avoid capture (even though this means
that strictly speaking, substitution is now not a function, since more than
one renaming is possible).

Terms which are the same if one safely (i.e., without capture) renames
bound variables are called $\alpha$-equivalent.  

Full $\beta$-reduction is the relation that allows the above
$\beta$-reduction step to take place anywhere in a term.  Since there
can be more than \emph{$\beta$-redex} (a term of the form
$(\lambda\,x.\, t)\ t'$) in a term, full $\beta$-reduction is
non-deterministic: it can happen that $t\leadsto t_1$ and $t\leadsto
t_2$, where $t_1$ and $t_2$ are different.  If for some similar
relation we instead have that $t_1$ always equals $t_2$ in this
situation, then the relation is \emph{deterministic}.  We will write
$\leadsto^*$ for the reflexive-transitive closure of $\leadsto$.  We
have $t \leadsto^* t'$ iff there is a finite sequence of
$\leadsto$-steps leading from $t$ to $t'$.  In other words, we allow
$0$ or more steps of $\beta$-reduction.

The relation of full $\beta$-reduction may be defined using the rules
of Figure~\ref{fig:fullbeta}.  Here is an example derivation using the
rules above to show that $\lambda x. x\ ((\lambda z.z\ z)\ x)$ reduces
to $\lambda x. x\ (x\ x)$.
\[
\infer[\textit{lam}]{\lambda\, x.\, (x\ ((\lambda z.z\ z)\ x))\ \leadsto\ \lambda\, x.\, (x\ (x\ x))}
      {\infer[\textit{app2}]{x\ ((\lambda\, z.\,(z\ z))\ x)\ \leadsto\ x\ (x\ x)}
       {\infer[\beta]{(\lambda\, z.\,(z\ z))\ x\ \leadsto x\ x}{\ }}}
\]
\noindent Generally, derivations are trees labeled by judgments of some kind (facts
to be proved by the rules).  The leaves are drawn at the top, and the root at the
bottom.  Edges between tree nodes are indicated with horizontal lines, showing
that an inference has been made using a particular rule.  Axioms are rules that
have no premises, and hence may be placed used at the leaves.
  
\begin{figure}
\[
\begin{array}{ll}
\betarule
&
\lamrule
\\ \\
\apparule
&
\appbrule
\end{array}
\]
\caption{Rules defining full $\beta$-reduction}
\label{fig:fullbeta}
\end{figure}


\subsection{Example of $\beta$-reduction}

Let \textit{id} abbreviate the term $\lambda\,x.\, x$, and if $n$ is a natural number (\{0,1,\ldots\}),
let $\dot{n}$ abbreviate
\[
\lambda\,s.\, \lambda\,z.\, \underbrace{(s \cdots (s}_n\ z)\cdots)
\]
\noindent This is the Church-encoding of number $n$.  Then for example, we have
\[
\dot{n}\ \textit{id} \leadsto^* \textit{id}
\]
\noindent This is because the whole term $\dot{n}\ \textit{id}$ itself is a $\beta$-redex
(lambda abstraction applied to argument), which reduces to
\[
\lambda\,z.\, \underbrace{(\textit{id} \cdots (\textit{id}}_n\ z)\cdots)
\]
\noindent Reducing (sequentially) the $n$ applications of \textit{id} results in $\lambda\,z.\, z$,
which is indeed $\alpha$-equivalent to \textit{id}.  This is an artificial example,
but one can define the usual arithmetic operations like addition, multiplication, etc., using
the Church encoding.

\textbf{Exercises:}
\begin{enumerate}
\item Write down a reduction sequence (i.e., a sequence of $\beta$-reductions like $t_1 \leadsto t_2 \leadsto \cdots$)
  from the following term to a normal form:
  \[
  (\lambda\,f.\,\lambda\, a.\, f\ (f\ a))\ (\lambda\,x.\,\lambda\, y.\, x)
  \]

\item For the previous example, how many different reduction sequences are there to a normal form?
\end{enumerate}


\subsection{Call-by-name reduction}

Functional programming languages generally do not implement full
$\beta$-reduction for their lambda calculus fragments, but rather some
\textbf{reduction strategy}.  This is a particular choice, for each
term, of a subset of its $\beta$-redexes that may be reduced next.
Below, we will show some of our normalization results for a strategy
called \textbf{call-by-name}.  This is a form of lazy reduction, where
we do not require arguments $t'$ to be reduced before reducing
$(\lambda\,x., t)\ t'$.  We can define single-step call-by-name
reduction with these inference rules:
\[
\begin{array}{lll}
\infer[\beta]{(\lambda\,x.\, t)\ t'\ \leadsto\ [t'/x]t}
      {\ }
&\ &
\infer[\textit{left}]{t_1\ t_2\ \leadsto\ t_1'\ t_2}
      {t_1\ \leadsto\ t_1'}      
\end{array}
\]
\noindent Rather than just stipulating, as we did for full
$\beta$-reduction, that any redex we find can be reduced, we here
require a finite derivation of $t\leadsto t'$ using these rules.  The
first rule is just the $\beta$ rule again, of course.  The second,
here called \emph{left},
quite restricts where that $\beta$ rule can be applied.  It can only
be applied in the left part of an application (or, using the $\beta$
rule directly, at the top level of the term).  
A derivation built using these two rules has a use of the $\beta$-rule at the sole leaf of tree,
followed by some sequence of uses of the \emph{left}-rule.   Here is an example derivation:
\[
\infer[\textit{left}]
      {(\lambda\,x.\, \lambda\,y.\, \lambda z.\, (y\ x))\ (\textit{id}\ \textit{id}) \ \textit{id}\ \leadsto\ 
      (\lambda\,y.\, \lambda\,z.\, (y\ (\textit{id}\ \textit{id})))\ \textit{id}}
      {\infer[\beta]{(\lambda\,x.\, \lambda\,y.\, \lambda z.\, (y\ x))\ (\textit{id}\ \textit{id})\ \leadsto\
          (\lambda\,y.\, \lambda\,z.\, (y\ (\textit{id}\ \textit{id})))}{\ }}
      \]
\noindent This derivation proves the single reduction step (at the bottom of the derivation)
  \[
(\lambda\,x.\, \lambda\,y.\, \lambda z.\, (y\ x))\ (\textit{id}\ \textit{id}) \ \textit{id}\ \leadsto\ 
(\lambda\,y.\, \lambda\,z.\, (y\ (\textit{id}\ \textit{id})))\ \textit{id} 
\]
\noindent We can write a call-by-name \emph{reduction sequence} beginning with this step:
\[
(\lambda\,x.\, \lambda\,y.\, \lambda z.\, (y\ x))\ (\textit{id}\ \textit{id}) \ \textit{id}\ \leadsto\ 
(\lambda\,y.\, \lambda\,z.\, (y\ (\textit{id}\ \textit{id})))\ \textit{id}\ \leadsto\
\lambda\,z.\, (\textit{id}\ (\textit{id}\ \textit{id}))
\]
\noindent The second reduction also has a derivation, just using the $\beta$-rule.
The final term of the reduction sequence -- i.e.,
$\lambda\,z.\, (\textit{id}\ (\textit{id}\ \textit{id}))$ -- is a
\emph{normal form} with respect to call-by-name reduction: it cannot
be reduced further with this relation.  This is because the rules do
not allow reduction underneath a $\lambda$-abstraction or in the right
part of an application, since the only rule for finding a
$\beta$-redex is \textit{left}.  This term is not a normal form with
respect to full $\beta$-reduction, however, because it has two
$\beta$-redexes in it, namely the two applications of \textit{id}.
This shows that normalization with call-by-name reduction might result
in a term that has $\beta$-redexes in it, in the body of a
$\lambda$-abstraction.  It could also happen, if one has free (undeclared)
variables in the term, that there could be a $\beta$-redex in the right part
of an application of a variable, as in $x\ (\textit{id}\ \textit{id})$.
But if the term is \textbf{closed} (no occurrences of variable $x$
except under some $\lambda$ that binds $x$), then terms which are normal
with respect to call-by-name reduction are $\lambda$-abstractions.
These might contain $\beta$-redexes in their bodies.

Call-by-name reduction is a deterministic strategy.

\subsection{The Simply Typed Lambda Calculus}

The Simply Typed Lambda Calculus (STLC) is a basic type system that
one finds as a subsystem of most practical type systems.  It is thus
of interest.  Type systems always come with some set of types.  The
simple types $T$ are defined over some unspecified set of base types
(in practice, these could be types like \verb|char| or \verb|int|):
\begin{eqnarray*}
\textit{base types}\ b\ &\ & \\
\textit{simple types}\ T & ::= & b\ |\ T_1 \to T_2
\end{eqnarray*}

In these notes, we use a Curry-style approach to typing, where the
type system specifies assignments of types to unannotated terms of
pure $\lambda$-calculus.  For example, intuitively, the term
\textit{id} can be assigned any type of the form $T \to T$; for
example, $b \to b$.  Church-style typing is more common, where terms
are annotated with types -- most commonly, for $\lambda$-bound
variables -- and these annotations are treated as essential parts of
the term.  It is perfectly reasonable to use annotations with
Curry-style typing, as hints to guide the type checker in applying the
typing rules, which might be nondeterministically applicable.  For
theoretical study, though, it is generally more convenient to disregard
the question of interpreting typing rules as a description of a typing
algorithm, and instead just view them as defining a mathematical relation
of typing between terms and types.

Actually, there is usually a third component for a typing judgment (that is,
a statement of typing that is to be derived using the typing rules).  This
is the \emph{typing context}, which is a list of assumptions of types for
variables:
\begin{eqnarray*}
\textit{typing contexts}\ \Gamma & ::= & \cdot\ |\ \Gamma, x : T
\end{eqnarray*}

\noindent The empty context, which declares types for no variables, is
written $\cdot$.  If $\Gamma$ is a context, then adding an assumption
that term variable $x$ has type $T$ is denoted $\Gamma,x : T$.  The
type-assignment rules for STLC are shown in Figure~\ref{fig:stlc}.  In
the first rule, for typing variables, the notation $\Gamma(x) = T$ is
used to mean that the result of looking up the first type for variable
$x$ in context $\Gamma$, starting from the right, is $T$.  

An example typing derivation is given in Figure~\ref{fig:stlcex}.  It
shows that in the empty context, $\lambda\,x.\,\lambda\,y.\,(x\ y)$
can be assigned the type $(T_1\to T_2)\to (T_1\to T_2)$, for any types
$T_1$ and $T_2$.

\begin{figure}
\[
\begin{array}{lll}
\infer{\Gamma\vdash x : T}{\Gamma(x) = T} 

&

\infer{\Gamma\vdash \lambda\,x.\,t : T_1 \to T_2}
      {\Gamma,x:T_1\vdash t:T_2}

&

\infer{\Gamma\vdash t_1\ t_2 : T_1}
      {\Gamma\vdash t_1 : T_2 \to T_1 &
       \Gamma\vdash t_2 : T_2}

\end{array}
\]
\caption{Type-assignment rules for simply typed lambda calculus}
\label{fig:stlc}
\end{figure}


\begin{figure}
\[
\infer{\cdot \vdash \lambda\,x.\, \lambda\,y.\,(x\ y) : (T_1\to T_2)\to
(T_1\to T_2)}
      {\infer{x:T_1 \to T_2 \vdash \lambda\,y.\,(x\ y) : T_1\to T_2}
             {\infer{x:T_1 \to T_2, y:T_1 \vdash (x\ y) : T_2}
                    {\infer{x:T_1 \to T_2, y:T_1 \vdash x : T_1 \to T_2}{\ } &
                     \infer{x:T_1 \to T_2, y:T_1 \vdash y : T_1}{\ }}}}
\]
\caption{Example typing derivation in STLC}
\label{fig:stlcex}
\end{figure}

\textbf{Exercises:} Write out typing derivations, using the rules of Figure~\ref{fig:stlc}, for
  the following typing judgments, assuming base types $a$, $b$, and $c$.  
  \begin{enumerate}
  \item $\cdot, x:b, y : b\to b \vdash y\ (y\ x) : b$
  \item $\cdot \vdash \lambda\,x.\,\lambda\,y.\,x : a \to (b \to a)$
  \item $\cdot \vdash \lambda\,x.\,\lambda\,y.\lambda\,z.\,((x\ z)\ (y\ z)) : (a \to (b \to c)) \to ((a \to b) \to (a \to c))$
  \end{enumerate}

\section{Normalization for the Simply Typed Lambda Calculus}

In this section, we will prove that terms that are statically typable
in a particular type system called the Simply Typed Lambda Calculus
(STLC) are normalizing with respect to full $\beta$-reduction.  Since
$\beta$-reduction is nondeterministic, an important issue is whether
we will prove that no matter which redex one chooses to reduce next,
reduction reaches a normal form; or instead that there exists a
particular choice of redex that guarantees reduction reaches a normal
form (but where it is conceivable that reduction could diverge if a
different strategy were applied).  Reduction no matter what strategy
is used is called \textbf{strong normalization} (also
\textbf{termination}), while reduction under some strategy (but
possibly not all) is called \textbf{weak normalization}, or just
normalization.  Here we will prove just weak normalization.

Quite a simple -- and to me, appealing -- proof of normalization for
terms typable in STLC can be given using a well-founded ordering
invented by Dershowitz and Manna~\cite{dm79}.  The idea of the
normalization proof is to define, for each typing derivation, a
certain measure.  This measure will be a multiset of types, one for
each redex we find in the typing derivation.  Then we will see a
particular reduction strategy (choice of next redex to reduce) that
always causes this measure to decrease in the Dershowitz-Manna
ordering.  The ordering is well-founded, which means that one cannot
decrease forever.  So eventually we will reach a minimal multiset of
types.  In this case, the minimal multiset will be the empty one, as
all redexes will have been reduced.

There are several ingredients to this proof, which we consider in turn.

\subsection{A measure of a typing derivation}

Suppose $\mathcal{D}$ is a typing derivation for judgment $\Gamma\vdash t : T$.  Then
define a measure $\mu(\mathcal{D})$ to be the multiset of types $T_2 \to T_1$ which occur in an
inference of the following form in $\mathcal{D}$:

\[ 
\infer{\Gamma \vdash (\lambda x.t)\ t' : T_1}
       {\infer{\Gamma \vdash (\lambda x.t) : T_2\to T_1}
              {\Gamma, x : T_2 \vdash t : T_1} & \Gamma \vdash t' : T_2}
\]
\noindent This inference is typing a $\beta$-redex $(\lambda x.t)\ t'$ by
typing the $\lambda$-abstraction at type $T_2\to T_1$.  For all such
typings of $\beta$-redexes in $\mathcal{D}$, the multiset $\mu(\mathcal{D})$
contains the type $T_2 \to T_1$.  Let us call such a type a \emph{redex type}
of $\mathcal{D}$.

For example, consider this typing derivation $\mathcal{D}$ for the term $\lambda\,x.\,(\textit{id}\ (\textit{id})\ x)$:
\[
\infer{\cdot\vdash \lambda\,x.\,(\textit{id}\ (\textit{id})\ x) : b \to b}
      {\infer{\cdot, x : b \vdash (\textit{id}\ (\textit{id})\ x) : b}
        {\infer{\cdot, x : b \vdash \textit{id} : \mathbf{b \to b}}{\infer{\cdot, x : b , x : b \vdash x : b}{\ }} &
          \infer{\cdot , x : b \vdash \textit{id}\ x : b}
                {\infer{\cdot, x : b \vdash \textit{id} : \mathbf{b \to b}}{\infer{\cdot, x : b , x : b \vdash x : b}{\ }} &
                  \infer{\cdot, x : b \vdash x : b}{\ }}}}
\]
\noindent The multiset $\mu(\mathcal{D})$ is $\{ b \to b, b \to b \}$,
because those types are included in the multiset at the bolded points
in the derivation.  (Recall that a multiset is like a set except that multiplicity
is taken into account.)  Let us say that we are just ordering types by their
size.

\subsection{The Dershowitz-Manna multiset ordering}

Dershowitz and Manna defined a very useful and influential ordering on finite multisets of elements of type $A$, extending
a strict partial order (transitive and irreflexive) on $A$~\cite{dm79}.  The definition is that a finite multiset $M$ is
greater than $M'$ (notation $M \ggcurly M'$) iff there are finite multisets $X$ and $Y$ such that
\[
M' = (M - X) \cup Y
\]
\noindent and further, for all $y\in Y$, there is some $x \in X$ such that $x > y$.  Dershowitz and Manna prove that this
is a strict partial order, and that it is well-founded iff the ordering on $A$ is.

For example, suppose that $A$ is the set of natural numbers, and we use the usual decreasing ordering on those.  Then
a multiset like $\{ 5, 5, 3 , 1 , 1 \}$ is greater than $\{ 4 , 4 , 4 , 4 , 5 , 3 , 1 , 0 , 0 , 0 \}$.  Here, the
multiset $X$ is $\{ 5, 1 \}$ and the multiset $Y$ is $\{ 4 , 4 , 4 , 4 , 0 , 0 , 0 \}$.  For every element of $Y$,
there is indeed a greater element of $X$.  The power of the ordering comes from the fact that there may be (finitely) many
elements of $Y$ dominated by a single element of $X$.  

\subsection{Type preservation: reduction preserves typing}

Our measure is going to be defined on typing derivations, but reduction
operates on terms of pure $\lambda$-calculus.  We must prove that we can
keep typing and reduction in synch: whenever we have $t \leadsto t'$ and
$\Gamma \vdash t : T$, then we also have $\Gamma \vdash t' : T$.  This
property is called \emph{type preservation}.

\vspace{.25cm}
\begin{theorem}[Type Preservation]
\label{thm:tppres}
If $\Gamma\vdash t : T$ and $t \leadsto t'$, then $\Gamma\vdash t' : T$.
\end{theorem}

This is a straightforward and intuitive property, which one generally
expects to hold for most type systems.  The proof is given in Section~\ref{sec:tppres}
in the Appendix.  The proof makes use of the following lemma, also proved in the Appendix:

\vspace{.25cm}
\begin{lemma}[Substitution]
\label{lem:stlcsubst}
If $\Gamma, x:T_2 \vdash t : T_1$ and $\Gamma \vdash t' : T_2$, then
$\Gamma \vdash [t'/x]t : T_1$.
\end{lemma}

\noindent This lemma says that substituting a term of type $T_2$ for a variable that
is assumed to have type $T_2$ preserves typing (while eliminating that
variable from the typing context).  This plays a crucial role in the next section.
  
\subsection{A reduction strategy that reduces the measure}
\label{sec:mudec}

The transformation implicit in the (constructive) proof of Theorem~\ref{thm:tppres}
could change the measure of a typing derivation only in the following situation.  The
proof of $t \leadsto t'$ ends in
\[ 
\betarule
\]
\noindent and the typing derivation ends in:
\begin{equation} 
\infer{\Gamma \vdash (\lambda x.t)\ t' : T_1}
       {\infer{\Gamma \vdash (\lambda x.t) : T_2\to T_1}
              {\Gamma, x : T_2 \vdash t : T_1} & \Gamma \vdash t' : T_2}
\tag{A}
\end{equation}
\noindent In this case, the proof of Theorem~\ref{thm:tppres} says
to transform this derivation into
\begin{equation}
\infer[\textit{Lemma}~\ref{lem:stlcsubst}]
      {\Gamma,\vdash [t'/x]t:T_1}
      {\Gamma, x : T_2 \vdash t : T_1 & \Gamma \vdash t' : T_2}
\tag{B}
\end{equation}
\noindent (That is, we use the derivation which the proof of Lemma~\ref{lem:stlcsubst} constructs
for the typing judgment with $[t'/x]t$).  We need to ensure that the measure of this derivation is smaller,
in the Dershowitz-Manna ordering, than the measure of the typing derivation
we started with.  We are going to remove one copy of $T_2 \to T_1$ from
the measure, when we transform (A) into (B).  For the measure to decrease,
we need to make sure that the only types we add to the multiset are smaller than $T_2 \to T_1$.
This would be a problem in the situation where the typing derivation for $t'$ contained a redex
type of the same size or larger than $T_2 \to T_1$, and the variable $x$ occurred multiple times in $t$.  For then
the proof of Lemma~\ref{lem:stlcsubst} would copy the typing derivation for $t'$
several times, and that redex type would get added additional times to the multiset.  The elimination
of one copy of $T_2 \to T_1$ would not suffice to cover those copied redex types (since we are assuming
the copied redex types are not smaller than $T_2 \to T_1$).

We can now see how to define our reduction strategy for terms with
typing derivation $\mathcal{D}$.  We may reduce redexes
$(\lambda\,x.\,t)\ t'$ as long as either $x$ does not occur more than
once in $t$, or else the redex type in $\mathcal{D}$ of the redex is
greater than the redex types of the redexes (if any) in the argument
$t'$.  Redexes of smaller redex type are allowed to be copied -- but
these copies are then covered by the elimination of the redex type of
$(\lambda\,x.\,t)\ t'$.

There is one final step of reasoning then required to show:

\vspace{.25cm}
\begin{theorem}
\label{thm:meas}
  Suppose $\mathcal{D}$ derives $\Gamma \vdash t : T$, and $t \leadsto t'$ using
  the strategy just described.
  Let $\mathcal{D}'$ be the derivation stated to exist by Theorem~\ref{thm:tppres}.
  Then $\mu(\mathcal{D}) \ggcurly \mu(\mathcal{D}')$.
\end{theorem}

\begin{proof}
  \noindent The final important consideration is that when we perform a $\beta$-reduction,
  we might create new redexes that were not present before in the term.  For example,
  in the following reduction, we create the redex $\textit{id}\ \textit{id}$:
  \[
  (\lambda\, x.\,(x\ \textit{id}))\ \textit{id} \ \leadsto
  \lambda\, x.\,(\textit{id} \ \textit{id})
  \]
  \noindent But when we have a redex with redex type $T_2\to T_1$, we are substituting
  an argument term of smaller type $T_2$ for the bound variable of the $\lambda$-abstraction.
  Following the proof of Lemma~\ref{lem:stlcsubst}, we will find that the redex type of
  redexes created by the substitution can only be $T_2$.  The addition of several redexes
  with redex type $T_2$ is covered, again thanks to the Dershowitz-Manna ordering, by the
  removal of the redex type $T_2 \to T_1$.
\end{proof}

\begin{corollary}
  If $\Gamma \vdash t : T$, then $t$ is normalizing.
\end{corollary}
\begin{proof} By the preceding theorem, if we reduce $t$ using the strategy
  that only reduces redexes $r$ whose redex type (in the associated typing derivation) is greater than the
  redex types of any redexes strictly within $r$, we will reduce the
  measure on the corresponding typing derivation.  Since the ordering
  in question is well-founded (since the ordering on types is), we
  must eventually reach a term $t'$ which cannot be further reduced
  using the strategy.  It suffices just to show that $t'$ really is a
  normal form.  For sake of contradiction, let $r$ be the smallest
  redex in $t'$.  Since it is smallest, it could be reduced by our
  strategy, since by definition it does not have any redexes within in
  it (and hence cannot have any with redex type of greater or equal
  size).  This contradicts the assumption that $t'$ cannot be further
  reduced with our strategy.
\end{proof}

\textbf{Exercises:} 
\begin{enumerate}
\item Underline all the redexes in this term:
  \[
  \cdot\vdash (\lambda\,q.\,\lambda\,h.\,((\lambda\, z.\,(q\ z\ z))\ ((\lambda\, y.\,y\, h)\ (\lambda\,x.\,x))))\ (\lambda\,u.\,\lambda\,v.\,u)
  \]
\item Confirm (informally, or with a full typing derivation) that this term can be assigned type $b$ if we make these assignments for the bound vvariables:
  \begin{itemize}
  \item $u : b$
  \item $v : b$    
  \item $h : b$
  \item $q : b \to (b \to b)$
  \item $z : b$
  \item $y : b \to b$
  \item $x : b$
  \end{itemize}

\item What are the redex types given this assignment of types to the bound variables?

\item Is there any redex that is not allowed by the above reduction strategy?

\item Show one reduction sequence that is allowed by our strategy, and which
  reaches a normal form.  Show the measure for the typing derivation associated
  with each term in the sequence (to confirm it is indeed decreasing).
\end{enumerate}

\section{Call-by-name Normalization for System F}

This section gives a proof that call-by-name reduction is normalizing
for unannotated System F (polymorphic lambda calculus).  System F is
defined with annotated terms, where $\lambda$-bound variables must be
declared with their types.  So we have $\lambda x:T.t$ instead of just
$\lambda x.t$.  For metatheoretic analysis, I prefer to work with
unannotated terms.  This system (with unannotated terms) is also
called $\lambda2$.

In addition to proving normalization, we will be able to draw an
easy corollary: 

Since System F includes STLC, the proof given here can be viewed as a
different way to prove a normalization property just for STLC (just
ignore the parts of the proof dealing with polymorphism).  But we
fundamentally need a different approach to normalization for System F,
because there is no known way to extend the measure we used in the
proof of the previous section, to work with the \emph{impredicative} polymorphism
of System F.  Impredicativity means that types may quantify over all types,
including themselves.  In contrast, predicative definitions may only
reference sets of previously constructed elements.

With impredicative polymorphism, the linchpin in the proof above of
Theorem~\ref{thm:meas} fails.  If we have a redex whose redex type is
of the form $(\forall X.T) \to T'$, then when we substitute the
argument term for the bound variable of type $\forall X.T$, we may end
up creating a redex with a much bigger redex type.  This is because
the variable might be applied to an argument in the body of the
$\lambda$-abstraction, after instantiating its type variable $X$ with
some large type.

The method of defining a compositional interpretation of simple types in
order to show normalization is due to Tait~\cite{tait67}.  It was extended by Girard
to handle impredicative polymorphism~\cite{girard72}.  An accessible source
for Girard's proof is~\citet{girard1989}, which
I recommend for learning more about these topics.

Proving just that call-by-name reduction normalizes is simpler than
proving normalization of full $\beta$-reduction, in one important
case.  For a $\lambda$-abstraction of type $T_1 \to T_2$, it could
happen that $T_1$ is an empty type (i.e., no terms have that type).
Then it requires some extra work to make sure that the body of the
$\lambda$-abstraction normalizes, even when a variable of empty type
is in scope.  It is simpler not to have to worry about that case.
Since call-by-name reduction does not descend under
$\lambda$-abstractions, we can avoid the issue, at the cost of a
weaker theorem: when reducing a closed term, $\beta$-redexes can still
occur in the final term, but only under $\lambda$-abstractions.

\subsection{Syntax}
\label{sec:syntax}

\[
\begin{array}{lll}
\textit{term variables}\ x & \ & \ \\
\textit{type variables}\ X & \ & \ \\
\textit{terms}\ t & ::= & x \ |\ \lambda x .t\ |\ t\ t'\\
\textit{types}\ T & ::= & X\ |\ T \to T'\ |\ \forall\, X.\, T
\end{array}
\]

The new form of type is $\forall\, X.\,T$.  This is a polymorphic
type, which intuitively means that for any type $T'$, $t$ can be typed
with the instance $[T'/X]T$.  

\subsection{Typing}

A typing context $\Gamma$ declares free term and type variables:
\[
\textit{Typing context }\Gamma ::= \cdot\ |\ \Gamma, x:T\ |\ \Gamma, X : \star
\]
We write $\Gamma(x) = T$ to mean looking up the first typing for $x$ in $\Gamma$,
starting from the right.The typing rules are in
Figure~\ref{fig:tp}.  To ensure that types are well-formed, we
use some extra rules, called \emph{kinding} rules, in Figure~\ref{fig:knd}.  

\begin{figure}
\[
\begin{array}{lllll}
\infer{\Gamma \vdash x : T}{\Gamma(x) = T & \Gamma \vdash T : \star} &\ \ \ &
\infer{\Gamma \vdash \lambda x . t : T \to T'}{\Gamma, x : T \vdash t : T'} &\ \ \ &
\infer{\Gamma \vdash t\ t' : T_2}{\Gamma \vdash t : T_1 \to T_2 & \Gamma \vdash t' : T_1} \\ \\
\infer{\Gamma \vdash t : \forall \,X.\,T}{\Gamma,X : \star \vdash t : T} &\ \ \ &
\infer{\Gamma \vdash t : [T'/X]T}{\Gamma \vdash t : \forall\, X.\,T & \Gamma \vdash T' : \star} &\ \ \ &\ 
\end{array}
\]
\caption{Typing rules for unannotated System F}
\label{fig:tp}
\end{figure}

\begin{figure}
\[
\begin{array}{lllll}
\infer{\Gamma \vdash X : \star}{\Gamma(X) = \star} &\ \ \ &
\infer{\Gamma \vdash T_1 \to T_2 : \star}{\Gamma \vdash T_1 : \star & \Gamma \vdash T_2 : \star} &\ \ \ &
\infer{\Gamma \vdash \forall\, X.\,T : \star}{\Gamma,X : \star \vdash T : \star}
\end{array}
\]
\caption{Kinding rules for unannotated System F}
\label{fig:knd}
\end{figure}

An example derivable typing is
\[
\cdot \vdash \lambda\,x.\,(x\ x) : \textit{Unit} \to \textit{Unit}
\]
\noindent where \textit{Unit} abbreviates $\forall\,X.\,(X \to X)$.  The
idea is that if $x$ has type \textit{Unit}, then we may apply it to an argument
of type $X$, and get back a result of type $X$, for any $X$.  So we may apply $x$
to itself, by instantiating $X$ with \textit{Unit}.  (So where we are using $x$ here
as a function, we are using it at type $\textit{Unit} \to \textit{Unit}$.)

The proof of the following theorem relating typing and kinding is straightforward and omitted.
The name ``regularity'' for the property expressed by the theorem is standard.
\vspace{.25cm}
\begin{theorem}[Regularity]
\label{thm:regularity}
If $\Gamma \vdash t : T$ then $\Gamma \vdash T:\star$.
\end{theorem}


\subsection{Semantics for types}
\label{sec:sem}

Figure~\ref{fig:semtp} gives a compositional semantics
$\interp{T}_\rho$ for types.  The function $\rho$ gives the
interpretations of free type variables in $T$.  Each free type
variable is interpreted as a \emph{reducibility candidate}, and we write
$\rho$ only for functions mapping type variables $X$ to reducibility
candidates.  To define what a reducibility candidate is: let us denote
the set of \underline{closed} terms which normalize using call-by-name
reduction as $\mathcal{N}$.  We will write $\leadsto$ for call-by-name
reduction. Then a reducibility candidate $R$ is a set of terms
satisfying the following requirements:
\begin{itemize}
\item $R \subseteq \mathcal{N}$
\item If $t\in R$ and $t'\leadsto t$, then $t'\in R$
\end{itemize}
In other words, it is a set of normalizing terms closed under $\beta$-expansion (the converse relation
of $\beta$-reduction).  The set of all reducibility candidates is denoted $\mathcal{R}$.

\vspace{0.25cm}

\begin{lemma}[$\mathcal{R}$ is a cpo]
  The set $\mathcal{R}$ ordered by subset forms a complete partial
  order: it has greatest element $\mathcal{N}$, and greatest lower bound
  of a nonempty set of elements of $\mathcal{R}$ given by
  intersection.
\end{lemma}

\vspace{0.25cm}

\begin{proof}
  $\mathcal{N}$ satisfies both requirements for a reducibility
  candidate, and since one of those requirements is being a subset of
  $\mathcal{N}$, it is clearly the largest such set to do so.  Let us
  prove that the intersection of a nonempty set $S$ of reducibility
  candidates is still a reducibility candidate.  Certainly if the
  members of $S$ are subsets of $\mathcal{N}$ then so is $\bigcap S$.
  For the second property: assume an arbitrary $t\in\bigcap S$ with
  $t'\leadsto t$, and show $t'\in\bigcap S$.  For the latter, it
  suffices to show $t'\in R$ for every $R\in S$.  Consider an
  arbitrary such $R$.  From $t\in\bigcap S$ and $R \in S$, we have
  $t\in R$.  Then since $R$ is expansion-closed (since it is a reducibility
  candidate), $t \in R$ and
  $t'\leadsto t$ implies $t'\in R$, .
\end{proof}

\begin{figure}
\[
\begin{array}{lll}
\interp{X}_\rho & = & \rho(X) \\ \\
\interp{T_1 \to T_2}_\rho & = & \{ t \in \mathcal{N}\ |\ \forall t'\in\interp{T_1}_\rho.\ t\ t'\in\interp{T_2}_\rho \} \\ \\
\interp{\forall\, X.\,T}_\rho & = & \bigcap_{R\in\mathcal{R}} \interp{T}_{\rho[X\mapsto R]} 
\end{array}
\]
\caption{Reducibility semantics for types}
\label{fig:semtp}
\end{figure}

\begin{lemma}[The semantics of types computes reducibility candidates]
\label{lem:semred}
  If $\rho(X)$ is defined for every free type variable of $T$, then
  $\interp{T}_\rho \in \mathcal{R}$.
\end{lemma}
\begin{proof}
  The proof is by induction on the structure of the type.  If $T$ is a
  type variable $X$, then by assumption, $\rho(X)$ is a reducibility
  candidate, and this is the value of $\interp{T}_\rho$.

  If $T$ is an arrow type $T_1 \to T_2$, we must prove the two
  properties listed above for being a reducibility candidate.
  Certainly $\interp{T}_\rho\subseteq\mathcal{N}$, because the
  semantics of arrow types requires this explicitly.  Now suppose that
  $t\in\interp{T_1\to T_2}_\rho$ and $t'\leadsto t$.  We must show
  $t'\in\interp{T_1\to T_2}_\rho$.  Since $t$ is normalizing and
  $t'\leadsto t$, we know that $t'$ is also normalizing (there is a
  reduction sequence from $t'$ to $t$ and from $t$ to a normal form).
  So let us assume an arbitrary $t''\in\interp{T_1}_\rho$, and show
  that $t'\ t''\in\interp{T_2}_\rho$.  Since $t' \leadsto t$, by the
  definition of call-by-name reduction, we have
\[
t'\ t'' \leadsto t\ t''
\]
Since $t\in\interp{T_1\to T_2}_\rho$, we know by the semantics of
types that $t\ t''\in\interp{T_2}_\rho$, since
$t''\in\interp{T_1}_\rho$.  By the IH, $\interp{T_2}_\rho$ is a
reducibility candidate.  So since $t'\ t''\leadsto t\ t''$ and $t\
t''\in\interp{T_2}_\rho$, we also have $t'\ t''\in\interp{T_2}_\rho$.
This was all we had to prove in this case.

Finally, if $T$ is a universal type $\forall\, X.\,T'$, then by IH, the
set $\interp{T'}_{\rho[X\mapsto R]}$ is a reducibility candidate for
all $R\in\mathcal{R}$.  Since $\mathcal{R}$ is a complete partial
order, $\bigcap_{R\in\mathcal{R}}\interp{T'}_{\rho[X\mapsto R]}$ is
then also a reducibility candidate.

\end{proof}

\subsection{Soundness of Typing Rules}

The goal of this section is to prove that terms which can be assigned
a type using the rules of Figure~\ref{fig:tp} are normalizing.  We
will actually prove a stronger statement, based on an interpretation
of typing judgments.  First, we must define an interpretation
$\interp{\Gamma}$ for typing contexts $\Gamma$.  This interpretation
will be a set of pairs $(\sigma,\rho)$, where $\rho$ is, as above, a
function mapping type variables to reducibility candidates; and
$\sigma$ maps term variables to terms.  The definition is by recursion
on the structure of $\Gamma$:
\[
\begin{array}{lll}
(\sigma,\rho)\in\interp{x:T,\Gamma} & \Leftrightarrow & \sigma(x)\in\interp{T}_\rho \ \wedge\ (\sigma,\rho)\in\interp{\Gamma} \\
(\sigma,\rho)\in\interp{X:*,\Gamma} & \Leftrightarrow & \rho(x)\in\mathcal{R}\ \wedge\ (\sigma,\rho)\in\interp{\Gamma} \\
(\sigma,\rho)\in\interp{\cdot}
\end{array}
\]
In the statement of the theorem below, we write $\sigma t$ to mean the
result of simultaneously substituting $\sigma(x)$ for $x$ in $t$, for
all $x$ in the domain of $\sigma$.

\vspace{0.25cm}
\begin{lemma}
\label{lem:ctxtext}
  Suppose $(\sigma,\rho)\in\interp{\Gamma}$.  If
  $t\in\interp{T}_\rho$, then $(\sigma[x\mapsto
  t],\rho)\in\interp{\Gamma,x:T}$.  Also, if $R\in\mathcal{R}$, then
  $(\sigma,\rho[x\mapsto R])\in\interp{\Gamma,X:*}$.
\end{lemma}
\begin{proof}
  The proof of the first part is by induction on $\Gamma$. If $\Gamma
  = \cdot$, then to show $(\sigma[x\mapsto
  t],\rho)\in\interp{\cdot,x:T}$, it suffices to show
  $t\in\interp{T}_\rho$, which holds by assumption.  If $\Gamma =
  y:T',\Gamma'$, then we have $(\sigma,\rho)\in\interp{\Gamma'}$ by
  the definition of $\interp{\Gamma}$, and we may apply the IH to
  conclude $(\sigma[x\mapsto t],\rho)\in\interp{\Gamma',x:T}$, from
  which we can conclude the desired $(\sigma[x\mapsto
  t],\rho)\in\interp{\Gamma,x:T}$, again by the definition of
  $\interp{\Gamma}$.  Similar reasoning applies if $\Gamma =
  X:\star,\Gamma'$.  The proof of the second part of the lemma
  is exactly analogous.
\end{proof}


\begin{theorem}[Soundness of typing rules with respect to the semantics]
\label{thm:snd}
If $\Gamma\vdash t : T$, then for all $(\sigma,\rho)\in\interp{\Gamma}$, we have $\sigma t \in\interp{T}_\rho$.
\end{theorem}
\begin{proof}
The proof is by induction on the structure of the assumed typing derivation.
In each case, we will implicitly assume an arbitrary $(\sigma,\rho)\in\interp{\Gamma}$.
Let us start with an easy case that shows the power of Tait's semantics for 

\underline{Case:}
\[
\infer{\Gamma \vdash t\ t' : T_2}{\Gamma \vdash t : T_1 \to T_2 & \Gamma \vdash t' : T_1} 
\]
By the IH, $\sigma t\in\interp{T_1 \to T_2}_\rho$ and $\sigma
t'\in\interp{T_1}_\rho$.  By the semantics of arrow types, this
immediately implies $(\sigma t)\ (\sigma t')\in\interp{T_2}_\rho$, as
required.



\underline{Case:}
\[
\infer{\Gamma \vdash x : T}{\Gamma(x) = T}
\]
We proceed by inner induction on $\Gamma$.  If $\Gamma$ is empty, then
$\Gamma(x) = T$ is false, and this case cannot arise.  Suppose
$\Gamma$ is of the form $x:T, \Gamma'$.  Then
$\sigma(x)\in\interp{T}_\rho$ by definition of $\interp{\Gamma}$,
which suffices to prove the conclusion.  Suppose $\Gamma$ is of the
form $y:T, \Gamma'$, where $y\neq x$, or of the form $X:*,\Gamma'$.
Then $\Gamma'(x) = T$ and $(\sigma,\rho)\in\interp{\Gamma'}$, and we
use the induction hypothesis to conclude $\sigma x\in\interp{T}_\rho$.

\underline{Case:}
\[
\infer{\Gamma \vdash \lambda x . t : T \to T'}{\Gamma, x : T \vdash t : T'} 
\]
All closed $\lambda$-abstractions are in $\mathcal{N}$.  So to prove $(\lambda x.\sigma t) \in \interp{T\to T'}_\rho$, it suffices
to assume an abitrary $t'\in\interp{T}_\rho$ and prove $(\lambda
x.\sigma t)\ t'\in\interp{T'}_\rho$.  Since $\interp{T'}_\rho$ is a
reducibility candidate, it suffices to prove $[t'/x]\sigma
t\in\interp{T'}_\rho$, since $(\lambda x.\sigma t)\ t' \leadsto
[t'/x](\sigma t)$ (using call-by-name reduction).  But if we let $\sigma'=\sigma[x\mapsto t']$, then
we have $(\sigma',\rho)\in\interp{\Gamma,x:T}$ by
Lemma~\ref{lem:ctxtext}, so we may apply the IH to conclude $\sigma'
t\in\interp{T'}_\rho$, as required.

\underline{Case:}
\[
\infer{\Gamma \vdash t : \forall\, X.\,T}{\Gamma,X : \star \vdash t : T} 
\]
We must prove $\sigma t\in\interp{\forall\, X.\,T}_\rho$.  By the
semantics of universal types, it suffices to assume an arbitrary
$R\in\mathcal{R}$, and prove $\sigma t\in\interp{T}_{\rho[X\mapsto
  R]}$.  But this follows by the IH, which we can apply because
$(\sigma,\rho[X\mapsto R])\in\interp{\Gamma, X:\star}$, by
Lemma~\ref{lem:ctxtext}.

\underline{Case:}
\[
\infer{\Gamma \vdash t : [T'/X]T}{\Gamma \vdash t : \forall\, X.\,T & \Gamma \vdash T' : \star} 
\]
By the IH, we know $\sigma t\in\interp{\forall\, X.\,T}_\rho$, which by the semantics
of universal types is equivalent to
\begin{equation}
\label{eq1}
\sigma t \in \bigcap_{R\in\mathcal{R}} T_{\rho[X\mapsto R]}
\end{equation}
Since $(\sigma,\rho)\in\interp{\Gamma}$, we may easily observe that
$\rho$ is defined for all the free type variables of $T'$.  So by
Lemma~\ref{lem:semred}, $\interp{T'}_\rho\in\mathcal{R}$.  From the
displayed formula above (\ref{eq1}), we can conclude $\sigma t\in
\interp{T}_{\rho[X\mapsto \interp{T'}_\rho]}$.  Now we must apply the
following lemma, whose easy proof by induction on $T$ we omit, to
conclude $\sigma t\in\interp{[T'/X]T}_\rho$.
\begin{lemma}
$\interp{[T'/X]T}_\rho = \interp{T}_{\rho[X\mapsto \interp{T'}_\rho]}$
\end{lemma}
\vspace{-.3cm}
\end{proof}

\begin{corollary}
  If $\cdot\vdash t : T$ is derivable in System F, then call-by-name reduction
  reaches a normal form from $t$.
\end{corollary}
\begin{proof}
  By Theorem~\ref{thm:snd}, we have $t \in \interp{T}_\emptyset$.  By Regularity (Theorem~\ref{thm:regularity}),
  we have $\cdot\vdash T : \star$.  Then $\interp{T}_\emptyset$ is
  a reducibility candidate by Lemma~\ref{lem:semred}.  This means it is a subset of $\mathcal{N}$.  So $t$ is
  call-by-name normalizing.
\end{proof}

A type is called \textbf{inhabited} iff there is some term that can be assigned
that type in the empty context.  

\vspace{0.25cm}
\begin{corollary}[Logical soundness]
  There is type $T$ which is uninhabited.
\end{corollary}
\begin{proof}
  The type is $\forall\,X.\,X$.  Suppose that there is some term $t$ with
  $\cdot\vdash t : \forall\,X.\,X$.  By Theorem~\ref{thm:snd}, we have $t \in \interp{\forall\,X.\,X}_\emptyset$.
  But the interpretation of $\forall\,X.\,X$ is the intersection of all reducibility candidates.
  Now $\emptyset$ is a reducibility candidate (according to the definition at the start of Section~\ref{sec:sem}).
  This is because it is a subset of $\mathcal{N}$ and is trivially expansion-closed.  But then $t\in\emptyset$,
  which is impossible.
  \end{proof}
  

\bibliography{biblio}

\appendix

\section{Proof of type preservation for STLC (Theorem~\ref{thm:tppres})}
\label{sec:tppres}

The proof is
  by induction on the structure of the derivation of $t \leadsto t'$.  

\ 

\noindent \underline{\textbf{Case:}}
\[
\apparule
\]
\noindent In this case, the $t$ mentioned in the theorem has been
refined to an application, $t_1\ t_2$.  There is only one typing rule that
can type an application, and so the typing derivation we are assuming
we have must end with this inference:

\[
\infer{\Gamma \vdash t_1\ t_2 : T_1}
      {\Gamma \vdash t_1 : T_2 \to T_1 & \Gamma \vdash t_2 : T_2}
\]

\noindent We may apply our induction hypothesis to the proof of $t_1\
\leadsto\ t_1'$ and the proof in the first premise of this inference,
to get:
\[ 
\Gamma \vdash t_1' : T_2\to T_1
\]

\noindent Putting this together with our proof of $\Gamma \vdash t_2 : T_2$
(from the second premise of the typing proof above), we have
\[
\infer{\Gamma \vdash t_1'\ t_2: T_1}
{\Gamma \vdash t_1' : T_2\to T_1 & \Gamma \vdash t_2:T_2}
\]

\noindent The case for the other application rule is similar, so we omit the details.

\ 

\noindent \underline{\textbf{Case:}}
\[
\lamrule
\]

\noindent Here, we have refined the $t$ from the statement of the theorem
to $\lambda\,x.\, t$.  Since there is only one typing rule that can type
a $\lambda$-abstraction, we know that our assumed typing derviation must
end in an inference of this form:
\[ 
\infer{\Gamma\vdash \lambda\,x.\,t : T_1 \to T_2}
      {\Gamma,x:T_1\vdash t:T_2}
\]
\noindent Then by our induction hypothesis applied to the derivation in
the premise of the reduction inference and the derivation in the premise
of the typing inference, we obtain:

\[ 
\Gamma, x:T_1 \vdash t' : T_2
\]
       
\noindent Now we may apply the rule for typing $\lambda$-abstractions get:

\[
\infer{\Gamma \vdash \lambda x. t' : T_1 \to T_2}
{\Gamma, x:T_1 \vdash t' : T_2}
\]

\noindent \underline{\textbf{Case:}}
\[ 
\betarule
\]

\noindent By similar reasoning about the possible form of the typing derivation, we may deduce
it ends in this form:

\[ 
\infer{\Gamma \vdash (\lambda x.t)\ t' : T_1}
       {\infer{\Gamma \vdash (\lambda x.t) : T_2\to T_1}
              {\Gamma, x : T_2 \vdash t : T_1} & \Gamma \vdash t' : T_2}
\]

\noindent To complete this case, it suffices to apply 
Lemma~\ref{lem:stlcsubst} to the premises of the above derivation:
\[
\infer[\textit{Lemma}~\ref{lem:stlcsubst}]
      {\Gamma,\vdash [t'/x]t:T_1}
      {\Gamma, x : T_2 \vdash t : T_1 & \Gamma \vdash t' : T_2}
\]


\section{Proofs of Weakening and Substitution Lemmas}
\label{sec:stlcsubst}

We will prove Lemma~\ref{lem:stlcsubst} in the following generalized form:
\begin{lemma}[Substitution]
\label{lem:stlcsubsta}
If $\Gamma_1, y:T_b, \Gamma_2 \vdash t_a : T_a$ and $\Gamma_1 \vdash t_b : T_b$, then
$\Gamma_1,\Gamma_2 \vdash [t_b/y]t_a : T_a$.
\end{lemma}

The proof relies on the
following lemma, which we prove first.

\begin{lemma}[Weakening]
\label{lem:stlcweak}
If $\Gamma_1, \Gamma_3 \vdash t_a : T_a$ then $\Gamma_1, \Gamma_2,
\Gamma_3 \vdash t_a : T_a$, assuming that the variables declared in
$\Gamma_2$ are disjoint from those declared in $\Gamma_1$ and
$\Gamma_3$.
\end{lemma}

\begin{proof}
The proof is by induction on the structure of the assumed derivation.

\ 

\noindent\underline{\textbf{Case:}}
\[
\infer{\Gamma_1,\Gamma_3\vdash x : T}{(\Gamma_1,\Gamma_3)(x) = T} 
\]
\noindent We can use this inference:
\[
\infer{\Gamma_1,\Gamma_2,\Gamma_3\vdash x : T}{(\Gamma_1,\Gamma_2\Gamma_3)(x) = T} 
\]

\noindent\underline{\textbf{Case:}}
\[
\infer{\Gamma_1,\Gamma_3\vdash \lambda\,x.\,t : T_1 \to T_2}
      {\Gamma_1,\Gamma_3,x:T_1\vdash t:T_2}
\]
\noindent We can use this derivation, where we are writing (as in Chapter~\ref{ch:opsemwhile})
applications of the induction hypothesis \textit{IH} as inferences in a derivation:
\[
\infer{\Gamma_1,\Gamma_2,\Gamma_3\vdash \lambda\,x.\,t : T_1 \to T_2}
      {\infer[\textit{IH}]{\Gamma_1,\Gamma_2,\Gamma_3,x:T_1\vdash t:T_2}{\Gamma_1,\Gamma_3,x:T_1\vdash t:T_2}}
\]
\noindent\underline{\textbf{Case:}}
\[
\infer{\Gamma_1,\Gamma_3\vdash t_1\ t_2 : T_1}
      {\Gamma_1,\Gamma_3\vdash t_1 : T_2 \to T_1 &
       \Gamma_1,\Gamma_3\vdash t_2 : T_2}
\]
\noindent We can use this derivation:
\[
\infer{\Gamma_1,\Gamma_3\vdash t_1\ t_2 : T_1}
      {\infer[\textit{IH}]{\Gamma_1,\Gamma_2,\Gamma_3\vdash t_1 : T_2 \to T_1}{\Gamma_1,\Gamma_3\vdash t_1 : T_2 \to T_1} &
       \infer[\textit{IH}]{\Gamma_1,\Gamma_2,\Gamma_3\vdash t_2 : T_2}{\Gamma_1,\Gamma_3\vdash t_2 : T_2}}
\]
\end{proof}

\noindent Now we can prove the Substitution Lemma:

\begin{proof}[Proof of Lemma~\ref{lem:stlcsubsta} (Substitution)]
The proof is by induction on the structure of the first assumed derivation.

\ 

\noindent \underline{\textbf{Case:}}
\[
\infer{\Gamma_1,y:T_b,\Gamma_2\vdash x : T_a}{\Gamma(x) = T_a} 
\]
\noindent Here, $t_a = x$.  We must case split on whether or not $x =
y$.  If so, then $[t_b/y]t_a = [t_b/y]y = t_b$, and $T_a = T_b$.  We
construct this derivation, where we are applying
Lemma~\ref{lem:stlcweak} (Weakening) as part of the derivation:
\[
\infer[\textit{Lemma}~\ref{lem:stlcweak}]{\Gamma_1,\Gamma_2\vdash t_b:T_b}{\Gamma_1\vdash t_b:T_b}
\]
\noindent If $x\neq y$, then we use the following derivation, where we know $x$ is declared
in $\Gamma_1,\Gamma_2$ since it is declared in $\Gamma = \Gamma_1,y:T_2,\Gamma_2$ and
$x\neq y$:
\[
\infer{\Gamma_1,\Gamma_2\vdash x : T_a}{(\Gamma_1,\Gamma_2)(x) = T_a} 
\]

\noindent \underline{\textbf{Case:}}
\[
\infer{\Gamma_1,y:T_b,\Gamma_2\vdash \lambda\,x.\,t : T_1\to T_2}{\Gamma_1,y:T_b,\Gamma_2,x:T_1\vdash t:T_2}
\]
\noindent We construct this derivation, where we may assume $x\neq y$, and so the term in
the conclusion, $\lambda\,x.\,[t_b/y]t$, equals the desired term $[t_b/y]\lambda\,x.\,t$:
\[
\infer{\Gamma_1,\Gamma_2\vdash \lambda\,x.\,[t_b/y]t : T_1\to T_2}
      {\infer[\textit{IH}]{\Gamma_1,\Gamma_2,x:T_1\vdash [t_b/y]t:T_2}{\Gamma_1,y:T_b,\Gamma_2,x:T_1\vdash t:T_2}}
\]

\noindent\underline{\textbf{Case:}}
\[
\infer{\Gamma_1,y:T_b,\Gamma_2\vdash t_1\ t_2 : T_1}
      {\Gamma_1,y:T_b,\Gamma_2\vdash t_1 : T_2 \to T_1 &
       \Gamma_1,y:T_b,\Gamma_2\vdash t_2 : T_2}
\]
\noindent We construct this derivation, where the term in the conclusion equals
the desired $[t_b/y](t_1\ t_2)$:
\[
\infer{\Gamma_1,\Gamma_2\vdash [t_b/y]t_1\ [t_b/y]t_2 : T_1}
      {\infer{\Gamma_1,\Gamma_2\vdash [t_b/y]t_1 : T_2 \to T_1}{\Gamma_1,y:T_b,\Gamma_2\vdash t_1 : T_2 \to T_1} &
       \infer{\Gamma_1,\Gamma_2\vdash [t_b/y]t_2 : T_2}{\Gamma_1,y:T_b,\Gamma_2\vdash t_2 : T_2}}
\]

\end{proof}


\end{document}
